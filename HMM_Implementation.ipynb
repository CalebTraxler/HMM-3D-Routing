{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e3a9986-d82a-4fc0-886c-6fc9b1ad0267",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "✓ Using Open3D for robust PLY loading\n",
      "KITTI-360 Premium VLM Image Generator\n",
      "==================================================\n",
      "Processing: 0000000002_0000000385.ply\n",
      "✓ Loaded 3,201,318 points using Open3D\n",
      "\n",
      "📊 Point Cloud Analysis:\n",
      "   Total points: 3,201,318\n",
      "   X range: 827.1 to 1007.7 m (180.6 m width)\n",
      "   Y range: 3670.5 to 3831.3 m (160.8 m depth)\n",
      "   Z range: 112.4 to 129.2 m (16.7 m height)\n",
      "\n",
      "🏗️  Scene Composition (Adaptive Thresholds):\n",
      "   Ground level (112.4 to 114.1m): 10,506 points (0.3%)\n",
      "   Object level (114.1 to 117.4m):  2,797,946 points (87.4%)\n",
      "   Structure level (>117.4m):     392,866 points (12.3%)\n",
      "\n",
      "🎨 Generating premium VLM images...\n",
      "Creating composite VLM image...\n",
      "  Scene dimensions: 180.6m x 160.8m\n",
      "Creating premium BEV image...\n",
      "  Coordinate ranges: X[827.1, 1007.7], Y[3670.5, 3831.3], Z[112.4, 129.2]\n",
      "  Height layers: Ground(10506), Low(2797946), Mid(374227), High(18639)\n",
      "    Valid points for this layer: 10506\n",
      "    Valid points for this layer: 2797944\n",
      "    Valid points for this layer: 374227\n",
      "    Valid points for this layer: 18639\n",
      "Creating premium range image...\n",
      "  Centered coordinates: X[-90.3, 90.3], Y[-80.4, 80.4], Z[-8.4, 8.4]\n",
      "  Range values: [3.7, 109.1]\n",
      "  Azimuth range: [-3.14, 3.14] radians\n",
      "  Elevation range: [-1.49, 0.36] radians\n",
      "  Valid pixels after filtering: 3041252\n",
      "Creating semantic density image...\n",
      "  Layer distribution: Ground(2234458), Objects(922391), Structures(44469)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 544\u001b[0m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    542\u001b[0m     ply_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcaleb\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mKITTI_3D\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata_3d_semantics\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata_3d_semantics\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m2013_05_28_drive_0000_sync\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mstatic\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m0000000002_0000000385.ply\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 544\u001b[0m     composite_image, point_cloud \u001b[38;5;241m=\u001b[39m process_ply_for_vlm(ply_file_path)\n\u001b[0;32m    546\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m    547\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🚀 READY FOR VLM PROCESSING!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 472\u001b[0m, in \u001b[0;36mprocess_ply_for_vlm\u001b[1;34m(ply_path)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m🎨 Generating premium VLM images...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    471\u001b[0m \u001b[38;5;66;03m# Create premium images\u001b[39;00m\n\u001b[1;32m--> 472\u001b[0m composite, bev, range_img, density \u001b[38;5;241m=\u001b[39m create_composite_vlm_image(points, colors, image_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;66;03m# Also create high-res individual images\u001b[39;00m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating high-resolution individual images...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 399\u001b[0m, in \u001b[0;36mcreate_composite_vlm_image\u001b[1;34m(points, colors, image_size)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(hist_normalized):\n\u001b[0;32m    398\u001b[0m     x \u001b[38;5;241m=\u001b[39m i \u001b[38;5;241m*\u001b[39m bin_width\n\u001b[1;32m--> 399\u001b[0m     y_start \u001b[38;5;241m=\u001b[39m half_size \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mint\u001b[39m(h) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m    400\u001b[0m     y_end \u001b[38;5;241m=\u001b[39m half_size \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m    401\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mrectangle(hist_img, (x, y_start), (x \u001b[38;5;241m+\u001b[39m bin_width \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, y_end), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "# KITTI-360 PLY to High-Quality VLM Images\n",
    "# Creates premium quality images optimized for Vision Language Model analysis\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import struct\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Try to import Open3D\n",
    "try:\n",
    "    import open3d as o3d\n",
    "    HAS_OPEN3D = True\n",
    "    print(\"✓ Using Open3D for robust PLY loading\")\n",
    "except ImportError:\n",
    "    HAS_OPEN3D = False\n",
    "    print(\"⚠ Using basic PLY parser\")\n",
    "\n",
    "def load_kitti360_ply(ply_path: str):\n",
    "    \"\"\"Load KITTI-360 PLY file with robust error handling\"\"\"\n",
    "    \n",
    "    if HAS_OPEN3D:\n",
    "        try:\n",
    "            pcd = o3d.io.read_point_cloud(ply_path)\n",
    "            points = np.asarray(pcd.points)\n",
    "            \n",
    "            colors = None\n",
    "            if pcd.has_colors():\n",
    "                colors = np.asarray(pcd.colors) * 255\n",
    "            \n",
    "            print(f\"✓ Loaded {len(points):,} points using Open3D\")\n",
    "            return points, colors\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Open3D failed: {e}\")\n",
    "            print(\"Falling back to basic parser...\")\n",
    "    \n",
    "    # Basic PLY parser\n",
    "    try:\n",
    "        with open(ply_path, 'rb') as f:\n",
    "            # Read header\n",
    "            header_lines = []\n",
    "            while True:\n",
    "                line = f.readline().decode('ascii', errors='ignore').strip()\n",
    "                header_lines.append(line)\n",
    "                if line == 'end_header':\n",
    "                    break\n",
    "            \n",
    "            # Parse header info\n",
    "            vertex_count = 0\n",
    "            properties = []\n",
    "            is_binary = False\n",
    "            \n",
    "            for line in header_lines:\n",
    "                if line.startswith('element vertex'):\n",
    "                    vertex_count = int(line.split()[-1])\n",
    "                elif line.startswith('property'):\n",
    "                    properties.append(line.split()[1:])\n",
    "                elif 'binary' in line:\n",
    "                    is_binary = True\n",
    "            \n",
    "            print(f\"PLY format: {'Binary' if is_binary else 'ASCII'}\")\n",
    "            print(f\"Vertices: {vertex_count:,}\")\n",
    "            \n",
    "            # Read data based on format\n",
    "            if is_binary:\n",
    "                points, colors = read_binary_ply_data(f, vertex_count, properties)\n",
    "            else:\n",
    "                points, colors = read_ascii_ply_data(f, vertex_count)\n",
    "            \n",
    "            if points is not None:\n",
    "                print(f\"✓ Loaded {len(points):,} points using basic parser\")\n",
    "            \n",
    "            return points, colors\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading PLY file: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def read_binary_ply_data(f, vertex_count, properties):\n",
    "    \"\"\"Read binary PLY data efficiently\"\"\"\n",
    "    data = []\n",
    "    \n",
    "    for i in range(vertex_count):\n",
    "        row = []\n",
    "        for prop in properties:\n",
    "            if len(prop) < 2:\n",
    "                continue\n",
    "                \n",
    "            prop_type = prop[0]\n",
    "            \n",
    "            if prop_type in ['float', 'float32']:\n",
    "                val = struct.unpack('<f', f.read(4))[0]\n",
    "            elif prop_type in ['double', 'float64']:\n",
    "                val = struct.unpack('<d', f.read(8))[0]\n",
    "            elif prop_type in ['uchar', 'uint8']:\n",
    "                val = struct.unpack('<B', f.read(1))[0]\n",
    "            elif prop_type in ['int', 'int32']:\n",
    "                val = struct.unpack('<i', f.read(4))[0]\n",
    "            else:\n",
    "                val = 0\n",
    "                \n",
    "            row.append(val)\n",
    "        \n",
    "        data.append(row)\n",
    "        \n",
    "        if i % 50000 == 0:\n",
    "            print(f\"Reading: {i:,}/{vertex_count:,}\")\n",
    "    \n",
    "    data = np.array(data)\n",
    "    points = data[:, :3]\n",
    "    colors = data[:, 3:6] if data.shape[1] >= 6 else None\n",
    "    \n",
    "    return points, colors\n",
    "\n",
    "def read_ascii_ply_data(f, vertex_count):\n",
    "    \"\"\"Read ASCII PLY data efficiently\"\"\"\n",
    "    data = []\n",
    "    \n",
    "    for i in range(vertex_count):\n",
    "        line = f.readline().decode('ascii', errors='ignore').strip()\n",
    "        if line:\n",
    "            values = list(map(float, line.split()))\n",
    "            data.append(values)\n",
    "        \n",
    "        if i % 50000 == 0:\n",
    "            print(f\"Reading: {i:,}/{vertex_count:,}\")\n",
    "    \n",
    "    data = np.array(data)\n",
    "    points = data[:, :3]\n",
    "    colors = data[:, 3:6] if data.shape[1] >= 6 else None\n",
    "    \n",
    "    return points, colors\n",
    "\n",
    "def create_premium_bev_image(points: np.ndarray, colors: np.ndarray = None, \n",
    "                           image_size: int = 2048, xy_range: float = 60) -> np.ndarray:\n",
    "    \"\"\"Create premium quality Bird's Eye View for VLM analysis\"\"\"\n",
    "    \n",
    "    print(\"Creating premium BEV image...\")\n",
    "    \n",
    "    # Get actual coordinate ranges for this dataset\n",
    "    x_min, x_max = np.min(points[:, 0]), np.max(points[:, 0])\n",
    "    y_min, y_max = np.min(points[:, 1]), np.max(points[:, 1])\n",
    "    z_min, z_max = np.min(points[:, 2]), np.max(points[:, 2])\n",
    "    \n",
    "    print(f\"  Coordinate ranges: X[{x_min:.1f}, {x_max:.1f}], Y[{y_min:.1f}, {y_max:.1f}], Z[{z_min:.1f}, {z_max:.1f}]\")\n",
    "    \n",
    "    # Adaptive height filtering based on actual data range\n",
    "    z_span = z_max - z_min\n",
    "    if z_span > 10:  # Large buildings/structures\n",
    "        ground_threshold = z_min + z_span * 0.1\n",
    "        low_threshold = z_min + z_span * 0.3\n",
    "        mid_threshold = z_min + z_span * 0.6\n",
    "        high_threshold = z_min + z_span * 0.9\n",
    "    else:  # More typical scene\n",
    "        ground_threshold = z_min + 2\n",
    "        low_threshold = z_min + 4\n",
    "        mid_threshold = z_min + 8\n",
    "        high_threshold = z_min + 12\n",
    "    \n",
    "    ground_mask = (points[:, 2] >= z_min) & (points[:, 2] <= ground_threshold)\n",
    "    low_mask = (points[:, 2] > ground_threshold) & (points[:, 2] <= low_threshold)\n",
    "    mid_mask = (points[:, 2] > low_threshold) & (points[:, 2] <= mid_threshold)\n",
    "    high_mask = (points[:, 2] > mid_threshold) & (points[:, 2] <= z_max)\n",
    "    \n",
    "    print(f\"  Height layers: Ground({np.sum(ground_mask)}), Low({np.sum(low_mask)}), Mid({np.sum(mid_mask)}), High({np.sum(high_mask)})\")\n",
    "    \n",
    "    # Create high-resolution BEV\n",
    "    bev_image = np.zeros((image_size, image_size, 3), dtype=np.uint8)\n",
    "    \n",
    "    def add_layer_to_bev(point_subset, color_rgb, alpha=0.8):\n",
    "        if len(point_subset) == 0:\n",
    "            return\n",
    "            \n",
    "        # Convert to image coordinates using actual coordinate ranges\n",
    "        x_img = ((point_subset[:, 0] - x_min) / (x_max - x_min) * image_size).astype(int)\n",
    "        y_img = ((point_subset[:, 1] - y_min) / (y_max - y_min) * image_size).astype(int)\n",
    "        \n",
    "        # Keep valid points\n",
    "        valid_mask = (x_img >= 0) & (x_img < image_size) & (y_img >= 0) & (y_img < image_size)\n",
    "        x_valid = x_img[valid_mask]\n",
    "        y_valid = y_img[valid_mask]\n",
    "        \n",
    "        print(f\"    Valid points for this layer: {len(x_valid)}\")\n",
    "        \n",
    "        # Add points with specified color (more efficient vectorized approach)\n",
    "        if len(x_valid) > 0:\n",
    "            for x, y in zip(x_valid, y_valid):\n",
    "                # Blend with existing pixels for better visualization\n",
    "                existing = bev_image[y, x].astype(float)\n",
    "                new_color = np.array(color_rgb, dtype=float)\n",
    "                blended = (1 - alpha) * existing + alpha * new_color\n",
    "                bev_image[y, x] = np.clip(blended, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    # Add layers with semantic colors\n",
    "    add_layer_to_bev(points[ground_mask], [60, 60, 60], alpha=0.9)      # Dark gray for ground\n",
    "    add_layer_to_bev(points[low_mask], [255, 200, 0], alpha=0.8)        # Yellow for vehicles/objects\n",
    "    add_layer_to_bev(points[mid_mask], [0, 150, 255], alpha=0.7)        # Blue for mid-level structures\n",
    "    add_layer_to_bev(points[high_mask], [255, 100, 100], alpha=0.6)     # Red for high structures\n",
    "    \n",
    "    # Apply Gaussian blur for smoother appearance\n",
    "    bev_image = cv2.GaussianBlur(bev_image, (3, 3), 0)\n",
    "    \n",
    "    # Enhance contrast\n",
    "    bev_image = cv2.convertScaleAbs(bev_image, alpha=1.2, beta=10)\n",
    "    \n",
    "    return bev_image\n",
    "\n",
    "def create_premium_range_image(points: np.ndarray, image_size: int = 2048) -> np.ndarray:\n",
    "    \"\"\"Create premium range image with enhanced features\"\"\"\n",
    "    \n",
    "    print(\"Creating premium range image...\")\n",
    "    \n",
    "    # Center the coordinates for better spherical projection\n",
    "    x_center = (np.min(points[:, 0]) + np.max(points[:, 0])) / 2\n",
    "    y_center = (np.min(points[:, 1]) + np.max(points[:, 1])) / 2\n",
    "    z_center = (np.min(points[:, 2]) + np.max(points[:, 2])) / 2\n",
    "    \n",
    "    # Translate to center\n",
    "    x = points[:, 0] - x_center\n",
    "    y = points[:, 1] - y_center  \n",
    "    z = points[:, 2] - z_center\n",
    "    \n",
    "    print(f\"  Centered coordinates: X[{np.min(x):.1f}, {np.max(x):.1f}], Y[{np.min(y):.1f}, {np.max(y):.1f}], Z[{np.min(z):.1f}, {np.max(z):.1f}]\")\n",
    "    \n",
    "    # Calculate spherical coordinates\n",
    "    range_vals = np.sqrt(x**2 + y**2 + z**2)\n",
    "    azimuth = np.arctan2(y, x)  # -π to π\n",
    "    elevation = np.arctan2(z, np.sqrt(x**2 + y**2))  # -π/2 to π/2\n",
    "    \n",
    "    print(f\"  Range values: [{np.min(range_vals):.1f}, {np.max(range_vals):.1f}]\")\n",
    "    print(f\"  Azimuth range: [{np.min(azimuth):.2f}, {np.max(azimuth):.2f}] radians\")\n",
    "    print(f\"  Elevation range: [{np.min(elevation):.2f}, {np.max(elevation):.2f}] radians\")\n",
    "    \n",
    "    # Enhanced image coordinate mapping\n",
    "    h_img = ((azimuth + np.pi) / (2 * np.pi) * image_size).astype(int)\n",
    "    v_img = ((elevation + np.pi/2) / np.pi * image_size).astype(int)\n",
    "    \n",
    "    # Filter valid pixels\n",
    "    max_range = np.percentile(range_vals, 95)  # Use 95th percentile as max range\n",
    "    valid_mask = (h_img >= 0) & (h_img < image_size) & (v_img >= 0) & (v_img < image_size) & (range_vals <= max_range)\n",
    "    h_valid = h_img[valid_mask]\n",
    "    v_valid = v_img[valid_mask]\n",
    "    range_valid = range_vals[valid_mask]\n",
    "    \n",
    "    print(f\"  Valid pixels after filtering: {len(h_valid)}\")\n",
    "    \n",
    "    # Create high-resolution range image\n",
    "    range_image = np.zeros((image_size, image_size), dtype=np.float32)\n",
    "    count_image = np.zeros((image_size, image_size), dtype=np.float32)\n",
    "    \n",
    "    # Accumulate ranges for averaging (handles multiple points per pixel)\n",
    "    for h, v, r in zip(h_valid, v_valid, range_valid):\n",
    "        range_image[v, h] += r\n",
    "        count_image[v, h] += 1\n",
    "    \n",
    "    # Average overlapping points\n",
    "    mask = count_image > 0\n",
    "    if np.sum(mask) > 0:\n",
    "        range_image[mask] /= count_image[mask]\n",
    "        \n",
    "        # Apply median filter to reduce noise\n",
    "        range_image = cv2.medianBlur(range_image.astype(np.float32), 3)\n",
    "        \n",
    "        # Enhanced colorization\n",
    "        range_max = np.max(range_image[range_image > 0])\n",
    "        if range_max > 0:\n",
    "            range_normalized = np.clip(range_image / range_max * 255, 0, 255).astype(np.uint8)\n",
    "        else:\n",
    "            range_normalized = np.zeros_like(range_image, dtype=np.uint8)\n",
    "    else:\n",
    "        print(\"  Warning: No valid range data found, creating empty image\")\n",
    "        range_normalized = np.zeros((image_size, image_size), dtype=np.uint8)\n",
    "    \n",
    "    # Use a better colormap\n",
    "    range_rgb = cv2.applyColorMap(range_normalized, cv2.COLORMAP_TURBO)\n",
    "    \n",
    "    # Enhance contrast and brightness\n",
    "    range_rgb = cv2.convertScaleAbs(range_rgb, alpha=1.1, beta=5)\n",
    "    \n",
    "    return range_rgb\n",
    "\n",
    "def create_semantic_density_image(points: np.ndarray, image_size: int = 2048, xy_range: float = 60) -> np.ndarray:\n",
    "    \"\"\"Create semantic density image showing object distributions\"\"\"\n",
    "    \n",
    "    print(\"Creating semantic density image...\")\n",
    "    \n",
    "    # Get actual coordinate ranges\n",
    "    x_min, x_max = np.min(points[:, 0]), np.max(points[:, 0])\n",
    "    y_min, y_max = np.min(points[:, 1]), np.max(points[:, 1])\n",
    "    z_min, z_max = np.min(points[:, 2]), np.max(points[:, 2])\n",
    "    \n",
    "    # Adaptive height layers based on actual data\n",
    "    z_span = z_max - z_min\n",
    "    if z_span > 10:  # Large buildings/structures\n",
    "        ground_threshold = z_min + z_span * 0.2\n",
    "        object_threshold = z_min + z_span * 0.5\n",
    "    else:  # More typical scene\n",
    "        ground_threshold = z_min + 2\n",
    "        object_threshold = z_min + 6\n",
    "    \n",
    "    # Create multi-layer density maps\n",
    "    layers = {\n",
    "        'ground': (points[:, 2] >= z_min) & (points[:, 2] <= ground_threshold),\n",
    "        'objects': (points[:, 2] > ground_threshold) & (points[:, 2] <= object_threshold),\n",
    "        'structures': (points[:, 2] > object_threshold)\n",
    "    }\n",
    "    \n",
    "    print(f\"  Layer distribution: Ground({np.sum(layers['ground'])}), Objects({np.sum(layers['objects'])}), Structures({np.sum(layers['structures'])})\")\n",
    "    \n",
    "    final_image = np.zeros((image_size, image_size, 3), dtype=np.float32)\n",
    "    \n",
    "    for layer_name, mask in layers.items():\n",
    "        if not mask.any():\n",
    "            continue\n",
    "            \n",
    "        layer_points = points[mask]\n",
    "        \n",
    "        # Create density grid\n",
    "        grid_size = 400  # High resolution internal grid\n",
    "        density_grid = np.zeros((grid_size, grid_size), dtype=np.float32)\n",
    "        \n",
    "        # Map points to grid using actual coordinate ranges\n",
    "        x_grid = ((layer_points[:, 0] - x_min) / (x_max - x_min) * grid_size).astype(int)\n",
    "        y_grid = ((layer_points[:, 1] - y_min) / (y_max - y_min) * grid_size).astype(int)\n",
    "        \n",
    "        # Count points in each cell\n",
    "        valid_mask = (x_grid >= 0) & (x_grid < grid_size) & (y_grid >= 0) & (y_grid < grid_size)\n",
    "        x_valid = x_grid[valid_mask]\n",
    "        y_valid = y_grid[valid_mask]\n",
    "        \n",
    "        for x, y in zip(x_valid, y_valid):\n",
    "            density_grid[y, x] += 1\n",
    "        \n",
    "        # Apply Gaussian smoothing\n",
    "        density_grid = cv2.GaussianBlur(density_grid, (15, 15), 0)\n",
    "        \n",
    "        # Resize to final image size\n",
    "        density_resized = cv2.resize(density_grid, (image_size, image_size))\n",
    "        \n",
    "        # Normalize\n",
    "        if np.max(density_resized) > 0:\n",
    "            density_normalized = density_resized / np.max(density_resized)\n",
    "        else:\n",
    "            density_normalized = density_resized\n",
    "        \n",
    "        # Assign to color channels\n",
    "        if layer_name == 'ground':\n",
    "            final_image[:, :, 2] += density_normalized * 255  # Blue channel\n",
    "        elif layer_name == 'objects':\n",
    "            final_image[:, :, 1] += density_normalized * 255  # Green channel\n",
    "        else:  # structures\n",
    "            final_image[:, :, 0] += density_normalized * 255  # Red channel\n",
    "    \n",
    "    # Normalize and convert to uint8\n",
    "    final_image = np.clip(final_image, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    # Enhance contrast\n",
    "    final_image = cv2.convertScaleAbs(final_image, alpha=1.1, beta=5)\n",
    "    \n",
    "    return final_image\n",
    "\n",
    "def create_composite_vlm_image(points: np.ndarray, colors: np.ndarray = None, \n",
    "                              image_size: int = 1024) -> np.ndarray:\n",
    "    \"\"\"Create a composite image combining multiple views for comprehensive VLM analysis\"\"\"\n",
    "    \n",
    "    print(\"Creating composite VLM image...\")\n",
    "    \n",
    "    # Get coordinate ranges for adaptive processing\n",
    "    x_range = np.max(points[:, 0]) - np.min(points[:, 0])\n",
    "    y_range = np.max(points[:, 1]) - np.min(points[:, 1])\n",
    "    max_range = max(x_range, y_range)\n",
    "    \n",
    "    print(f\"  Scene dimensions: {x_range:.1f}m x {y_range:.1f}m\")\n",
    "    \n",
    "    # Create individual high-quality images\n",
    "    bev = create_premium_bev_image(points, colors, image_size, xy_range=max_range/2)\n",
    "    range_img = create_premium_range_image(points, image_size)\n",
    "    density = create_semantic_density_image(points, image_size, xy_range=max_range/2)\n",
    "    \n",
    "    # Resize for composite (use half size for each quadrant)\n",
    "    half_size = image_size // 2\n",
    "    bev_small = cv2.resize(bev, (half_size, half_size))\n",
    "    range_small = cv2.resize(range_img, (half_size, half_size))\n",
    "    density_small = cv2.resize(density, (half_size, half_size))\n",
    "    \n",
    "    # Create height histogram as an image\n",
    "    hist, bins = np.histogram(points[:, 2], bins=50, range=(-5, 20))\n",
    "    hist_img = np.zeros((half_size, half_size, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Draw histogram\n",
    "    hist_normalized = hist / np.max(hist) * (half_size - 20)\n",
    "    bin_width = half_size // len(hist)\n",
    "    \n",
    "    for i, h in enumerate(hist_normalized):\n",
    "        x = i * bin_width\n",
    "        y_start = half_size - int(h) - 10\n",
    "        y_end = half_size - 10\n",
    "        cv2.rectangle(hist_img, (x, y_start), (x + bin_width - 1, y_end), (0, 255, 255), -1)\n",
    "    \n",
    "    # Add labels and grid\n",
    "    cv2.putText(hist_img, \"Height Distribution\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "    \n",
    "    # Combine into composite\n",
    "    composite = np.zeros((image_size, image_size, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Top row: BEV and Range\n",
    "    composite[:half_size, :half_size] = bev_small\n",
    "    composite[:half_size, half_size:] = range_small\n",
    "    \n",
    "    # Bottom row: Density and Stats\n",
    "    composite[half_size:, :half_size] = density_small\n",
    "    composite[half_size:, half_size:] = hist_img\n",
    "    \n",
    "    # Add border lines\n",
    "    cv2.line(composite, (half_size, 0), (half_size, image_size), (255, 255, 255), 2)\n",
    "    cv2.line(composite, (0, half_size), (image_size, half_size), (255, 255, 255), 2)\n",
    "    \n",
    "    # Add labels\n",
    "    cv2.putText(composite, \"Bird's Eye View\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "    cv2.putText(composite, \"Range Image\", (half_size + 10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "    cv2.putText(composite, \"Semantic Density\", (10, half_size + 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "    \n",
    "    return composite, bev, range_img, density\n",
    "\n",
    "def process_ply_for_vlm(ply_path: str):\n",
    "    \"\"\"Process PLY file and create premium images for VLM analysis\"\"\"\n",
    "    \n",
    "    print(\"KITTI-360 Premium VLM Image Generator\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Processing: {Path(ply_path).name}\")\n",
    "    \n",
    "    # Load point cloud\n",
    "    points, colors = load_kitti360_ply(ply_path)\n",
    "    \n",
    "    if points is None:\n",
    "        print(\"❌ Failed to load point cloud\")\n",
    "        return None\n",
    "    \n",
    "    # Print detailed statistics\n",
    "    print(f\"\\n📊 Point Cloud Analysis:\")\n",
    "    print(f\"   Total points: {len(points):,}\")\n",
    "    print(f\"   X range: {np.min(points[:, 0]):.1f} to {np.max(points[:, 0]):.1f} m ({np.max(points[:, 0])-np.min(points[:, 0]):.1f} m width)\")\n",
    "    print(f\"   Y range: {np.min(points[:, 1]):.1f} to {np.max(points[:, 1]):.1f} m ({np.max(points[:, 1])-np.min(points[:, 1]):.1f} m depth)\")\n",
    "    print(f\"   Z range: {np.min(points[:, 2]):.1f} to {np.max(points[:, 2]):.1f} m ({np.max(points[:, 2])-np.min(points[:, 2]):.1f} m height)\")\n",
    "    \n",
    "    # Analyze content with adaptive thresholds\n",
    "    z_min, z_max = np.min(points[:, 2]), np.max(points[:, 2])\n",
    "    z_span = z_max - z_min\n",
    "    \n",
    "    if z_span > 10:  # Large buildings/structures\n",
    "        ground_threshold = z_min + z_span * 0.1\n",
    "        object_threshold = z_min + z_span * 0.3\n",
    "    else:  # More typical scene\n",
    "        ground_threshold = z_min + 2\n",
    "        object_threshold = z_min + 6\n",
    "    \n",
    "    ground_points = np.sum((points[:, 2] >= z_min) & (points[:, 2] <= ground_threshold))\n",
    "    object_points = np.sum((points[:, 2] > ground_threshold) & (points[:, 2] <= object_threshold))\n",
    "    structure_points = np.sum(points[:, 2] > object_threshold)\n",
    "    \n",
    "    print(f\"\\n🏗️  Scene Composition (Adaptive Thresholds):\")\n",
    "    print(f\"   Ground level ({z_min:.1f} to {ground_threshold:.1f}m): {ground_points:,} points ({ground_points/len(points)*100:.1f}%)\")\n",
    "    print(f\"   Object level ({ground_threshold:.1f} to {object_threshold:.1f}m):  {object_points:,} points ({object_points/len(points)*100:.1f}%)\")\n",
    "    print(f\"   Structure level (>{object_threshold:.1f}m):     {structure_points:,} points ({structure_points/len(points)*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n🎨 Generating premium VLM images...\")\n",
    "    \n",
    "    # Create premium images\n",
    "    composite, bev, range_img, density = create_composite_vlm_image(points, colors, image_size=1024)\n",
    "    \n",
    "    # Also create high-res individual images\n",
    "    print(\"Creating high-resolution individual images...\")\n",
    "    x_range = np.max(points[:, 0]) - np.min(points[:, 0])\n",
    "    y_range = np.max(points[:, 1]) - np.min(points[:, 1])\n",
    "    max_range = max(x_range, y_range)\n",
    "    bev_hires = create_premium_bev_image(points, colors, image_size=2048, xy_range=max_range/2)\n",
    "    \n",
    "    # Save images\n",
    "    output_dir = Path(\"vlm_images\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    filename_base = Path(ply_path).stem\n",
    "    \n",
    "    # Save all versions\n",
    "    cv2.imwrite(str(output_dir / f\"{filename_base}_composite_vlm.jpg\"), composite)\n",
    "    cv2.imwrite(str(output_dir / f\"{filename_base}_bev_premium.jpg\"), bev_hires)\n",
    "    cv2.imwrite(str(output_dir / f\"{filename_base}_range_premium.jpg\"), range_img)\n",
    "    cv2.imwrite(str(output_dir / f\"{filename_base}_density_semantic.jpg\"), density)\n",
    "    \n",
    "    print(f\"\\n✅ Premium VLM images saved to {output_dir}/\")\n",
    "    print(f\"   📸 {filename_base}_composite_vlm.jpg (1024x1024) - BEST FOR VLM\")\n",
    "    print(f\"   📸 {filename_base}_bev_premium.jpg (2048x2048) - High-res BEV\")\n",
    "    print(f\"   📸 {filename_base}_range_premium.jpg (2048x2048) - High-res Range\")\n",
    "    print(f\"   📸 {filename_base}_density_semantic.jpg (2048x2048) - Semantic Density\")\n",
    "    \n",
    "    # Display the composite image\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.imshow(cv2.cvtColor(composite, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f'Premium VLM Image: {filename_base}', fontsize=16, fontweight='bold')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Add comprehensive description\n",
    "    description_text = f\"\"\"\n",
    "KITTI-360 Scene Analysis: {filename_base}\n",
    "\n",
    "COMPREHENSIVE VLM IMAGE (1024x1024):\n",
    "✅ Top-Left: Bird's Eye View (Adaptive Height Layers)\n",
    "✅ Top-Right: Range/Depth Image (Spherical Projection)  \n",
    "✅ Bottom-Left: Semantic Density (Multi-layer Object Distribution)\n",
    "✅ Bottom-Right: Height Distribution Analysis\n",
    "\n",
    "Scene Statistics:\n",
    "• Total Points: {len(points):,}\n",
    "• Scene Dimensions: {np.max(points[:, 0])-np.min(points[:, 0]):.1f}m × {np.max(points[:, 1])-np.min(points[:, 1]):.1f}m × {np.max(points[:, 2])-np.min(points[:, 2]):.1f}m\n",
    "• Ground Coverage: {ground_points/len(points)*100:.1f}% (Z: {z_min:.1f}-{ground_threshold:.1f}m)\n",
    "• Object Density: {object_points/len(points)*100:.1f}% (Z: {ground_threshold:.1f}-{object_threshold:.1f}m)\n",
    "• Structure Coverage: {structure_points/len(points)*100:.1f}% (Z: >{object_threshold:.1f}m)\n",
    "\n",
    "OPTIMIZED FOR VLM ANALYSIS:\n",
    "🎯 Adaptive coordinate transformation for any scale\n",
    "🎯 Multi-perspective comprehensive view\n",
    "🎯 Clear structural and spatial relationships\n",
    "🎯 Enhanced feature visibility\n",
    "\"\"\"\n",
    "    \n",
    "    plt.figtext(0.02, 0.02, description_text, fontsize=10, fontfamily='monospace',\n",
    "                bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightblue\", alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\n🎯 RECOMMENDED FOR VLM: Use '{filename_base}_composite_vlm.jpg'\")\n",
    "    print(\"   This image contains comprehensive scene information in a single optimized view.\")\n",
    "    \n",
    "    return composite, points\n",
    "\n",
    "# Run the premium conversion\n",
    "if __name__ == \"__main__\":\n",
    "    ply_file_path = r\"C:\\Users\\caleb\\OneDrive\\Desktop\\KITTI_3D\\data_3d_semantics\\data_3d_semantics\\train\\2013_05_28_drive_0000_sync\\static\\0000000002_0000000385.ply\"\n",
    "    \n",
    "    composite_image, point_cloud = process_ply_for_vlm(ply_file_path)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"🚀 READY FOR VLM PROCESSING!\")\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f952b32-a185-4eae-b2e2-b10450b951ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
